{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resultStemming</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['chatgpt', 'optim', 'languag', 'model', 'dial...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['tri', 'talk', 'chatgpt', 'new', 'ai', 'syste...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['chatgpt', 'optim', 'languag', 'model', 'dial...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['thrill', 'share', 'chatgpt', 'new', 'model',...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['minut', 'ago', 'releas', 'new', 'chatgpt', '...</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219289</th>\n",
       "      <td>['softwar', 'project', 'tri', 'replic', 'chatg...</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219290</th>\n",
       "      <td>['ask', 'chatgpt', 'write', 'nye', 'joke', 'se...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219291</th>\n",
       "      <td>['chatgpt', 'disassembl', 'dissembl']</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219292</th>\n",
       "      <td>['predict', 'chatgpt', 'noth', 'realli', 'spec...</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219293</th>\n",
       "      <td>['chatgpt', 'neat', 'stuff', 'httpstcoqjjufzm']</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>219294 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           resultStemming   labels\n",
       "0       ['chatgpt', 'optim', 'languag', 'model', 'dial...  neutral\n",
       "1       ['tri', 'talk', 'chatgpt', 'new', 'ai', 'syste...     good\n",
       "2       ['chatgpt', 'optim', 'languag', 'model', 'dial...  neutral\n",
       "3       ['thrill', 'share', 'chatgpt', 'new', 'model',...     good\n",
       "4       ['minut', 'ago', 'releas', 'new', 'chatgpt', '...      bad\n",
       "...                                                   ...      ...\n",
       "219289  ['softwar', 'project', 'tri', 'replic', 'chatg...      bad\n",
       "219290  ['ask', 'chatgpt', 'write', 'nye', 'joke', 'se...     good\n",
       "219291              ['chatgpt', 'disassembl', 'dissembl']      bad\n",
       "219292  ['predict', 'chatgpt', 'noth', 'realli', 'spec...      bad\n",
       "219293    ['chatgpt', 'neat', 'stuff', 'httpstcoqjjufzm']  neutral\n",
       "\n",
       "[219294 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_latih = pd.read_csv('./output/data-clean-en.csv', encoding='utf-8')\n",
    "data_latih[['resultStemming', 'labels']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resultStemming</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['kawankawan', 'bingung', 'asingdengan', 'isti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['terimakasih', 'jelas', 'bantu']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['tolong', 'pin']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['ralat', 'bang', 'poin', 'chat', 'gpt', 'fine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['thanks', 'additional', 'info', 'mas']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>['ngga', 'paham', 'blas']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>['dr', 'indra', 'bsa', 'ngoding', 'ga']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>['t']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>['pohara']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240</th>\n",
       "      <td>['dahsyat']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1241 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         resultStemming\n",
       "0     ['kawankawan', 'bingung', 'asingdengan', 'isti...\n",
       "1                     ['terimakasih', 'jelas', 'bantu']\n",
       "2                                     ['tolong', 'pin']\n",
       "3     ['ralat', 'bang', 'poin', 'chat', 'gpt', 'fine...\n",
       "4               ['thanks', 'additional', 'info', 'mas']\n",
       "...                                                 ...\n",
       "1236                          ['ngga', 'paham', 'blas']\n",
       "1237            ['dr', 'indra', 'bsa', 'ngoding', 'ga']\n",
       "1238                                              ['t']\n",
       "1239                                         ['pohara']\n",
       "1240                                        ['dahsyat']\n",
       "\n",
       "[1241 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_uji = pd.read_csv('./output/data-clean-ind.csv', encoding='utf-8')\n",
    "data_uji[['resultStemming']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF data latih"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               word  tfidf_score\n",
      "0                                __     1.227053\n",
      "1                               ___     2.478431\n",
      "2                              ____     3.088597\n",
      "3                             _____     5.026893\n",
      "4                            ______     3.753742\n",
      "...                             ...          ...\n",
      "285473                        𝙬𝙤𝙧𝙧𝙮     0.309286\n",
      "285474                          𝙮𝙤𝙪     0.260824\n",
      "285475                   𝚊𝚛𝚝𝚒𝚏𝚒𝚌𝚒𝚊𝚕     0.433232\n",
      "285476  𝚒𝚗𝚝𝚎𝚕𝚕𝚒𝚐𝚎𝚗𝚌𝚎nhttpstcowhuujo     0.433232\n",
      "285477                  𝚒𝚗𝚝𝚎𝚛𝚟𝚒𝚎𝚠𝚎𝚍     0.433232\n",
      "\n",
      "[285478 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "X_latih = vectorizer.fit_transform(data_latih['resultStemming'])\n",
    "\n",
    "tfidf_sum = np.array(X_latih.sum(axis=0)).ravel()\n",
    "\n",
    "tfidf_df = pd.DataFrame({\n",
    "    'word': vectorizer.get_feature_names_out(),\n",
    "    'tfidf_score': tfidf_sum\n",
    "})\n",
    "\n",
    "print(tfidf_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF data uji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         word  tfidf_score\n",
      "0      aamiin     1.000000\n",
      "1        abal     0.310682\n",
      "2         abc     0.262327\n",
      "3        abdi     0.092280\n",
      "4       about     0.700067\n",
      "...       ...          ...\n",
      "3682    zaman     2.526454\n",
      "3683  zaremba     0.312446\n",
      "3684      zat     0.278978\n",
      "3685     zero     0.876446\n",
      "3686     zlrr     0.453418\n",
      "\n",
      "[3687 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "X_uji = vectorizer.fit_transform(data_uji['resultStemming'])\n",
    "\n",
    "tfidf_df = pd.DataFrame({\n",
    "    'word': vectorizer.get_feature_names_out(),\n",
    "    'tfidf_score': X_uji.toarray().sum(axis=0)\n",
    "})\n",
    "\n",
    "print(tfidf_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sebelum Oversampling, jumlah label 'POSITIF': 56011\n",
      "Sebelum Oversampling, jumlah label 'NEGATIF': 107796 \n",
      "Sebelum Oversampling, jumlah label 'NETRAL': 55487 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Sebelum Oversampling, jumlah label 'POSITIF': {}\".format(sum(data_latih['labels'] == 'good')))\n",
    "print(\"Sebelum Oversampling, jumlah label 'NEGATIF': {} \".format(sum(data_latih['labels'] == 'bad')))\n",
    "print(\"Sebelum Oversampling, jumlah label 'NETRAL': {} \\n\".format(sum(data_latih['labels'] == 'neutral')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE\n",
    "# !pip install imblearn\n",
    "\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m sm \u001b[38;5;241m=\u001b[39m SMOTE(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m      3\u001b[0m X_res, y_res \u001b[38;5;241m=\u001b[39m sm\u001b[38;5;241m.\u001b[39mfit_resample(X_latih, data_latih[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSebelum Oversampling, jumlah label \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPOSITIF\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28msum\u001b[39m(\u001b[43my_res\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabels\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgood\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSebelum Oversampling, jumlah label \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNEGATIF\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28msum\u001b[39m(y_res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbad\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSebelum Oversampling, jumlah label \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNETRAL\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28msum\u001b[39m(y_res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneutral\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n",
      "File \u001b[1;32mc:\\Users\\Dell 7300\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:981\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    978\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m    980\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m--> 981\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_hashable(key):\n\u001b[0;32m    984\u001b[0m     \u001b[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[0;32m    985\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    986\u001b[0m         \u001b[38;5;66;03m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Dell 7300\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:1089\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1088\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1089\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1090\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_get_values_for_loc(\u001b[38;5;28mself\u001b[39m, loc, label)\n",
      "File \u001b[1;32mc:\\Users\\Dell 7300\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\range.py:395\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m    393\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    394\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[1;32m--> 395\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mget_loc(key, method\u001b[38;5;241m=\u001b[39mmethod, tolerance\u001b[38;5;241m=\u001b[39mtolerance)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'labels'"
     ]
    }
   ],
   "source": [
    "sm = SMOTE(random_state=2)\n",
    "\n",
    "X_res, y_res = sm.fit_resample(X_latih, data_latih['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sebelum Oversampling, jumlah label 'POSITIF': 107796\n",
      "Sebelum Oversampling, jumlah label 'NEGATIF': 107796 \n",
      "Sebelum Oversampling, jumlah label 'NETRAL': 107796 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Sebelum Oversampling, jumlah label 'POSITIF': {}\".format(sum(y_res == 'good')))\n",
    "print(\"Sebelum Oversampling, jumlah label 'NEGATIF': {} \".format(sum(y_res == 'bad')))\n",
    "print(\"Sebelum Oversampling, jumlah label 'NETRAL': {} \\n\".format(sum(y_res == 'neutral')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores:  [0.55867528 0.56603482 0.58177433 0.58622716 0.58430997 0.69646557\n",
      " 0.71718359 0.71245246 0.7131548  0.69766219]\n",
      "Average cross-validation score:  0.6413940159466758\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(model, X_res, y_res, cv=10)\n",
    "\n",
    "print(\"Cross-validation scores: \", scores)\n",
    "print(\"Average cross-validation score: \", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
