{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@sn5301679  pertanyaanya negara ini sudah maju...</td>\n",
       "      <td>NEGATIF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@deppaykurniawan2016  Makanya itulah pentingn...</td>\n",
       "      <td>POSITIF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@sn5301679  isu sensitif dan sering jadi komo...</td>\n",
       "      <td>NEGATIF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@vivifitriasari  pernah pengalaman kerja di p...</td>\n",
       "      <td>NEGATIF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@deppaykurniawan2016  Wah kebetulan bgt ya ma...</td>\n",
       "      <td>POSITIF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@deppaykurniawan2016  Wah kebetulan bgt ya ma...</td>\n",
       "      <td>POSITIF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>@deppaykurniawan2016  Wah kebetulan bgt ya ma...</td>\n",
       "      <td>POSITIF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@deppaykurniawan2016  Wah kebetulan bgt ya ma...</td>\n",
       "      <td>POSITIF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>@deppaykurniawan2016  Wah kebetulan bgt ya ma...</td>\n",
       "      <td>POSITIF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>@deppaykurniawan2016  Wah kebetulan bgt ya ma...</td>\n",
       "      <td>POSITIF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>@deppaykurniawan2016  Wah kebetulan bgt ya ma...</td>\n",
       "      <td>POSITIF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>@vivifitriasari  o.. saya dulu pernah gawe di...</td>\n",
       "      <td>POSITIF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>@sn5301679  Sorry bro, bukan bermaksud merend...</td>\n",
       "      <td>NEGATIF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>@sn5301679  Sorry bro, bukan bermaksud merend...</td>\n",
       "      <td>NEGATIF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>@sn5301679  Sorry bro, bukan bermaksud merend...</td>\n",
       "      <td>NEGATIF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>@sn5301679  Sorry bro, bukan bermaksud merend...</td>\n",
       "      <td>NEGATIF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>@sn5301679  Sorry bro, bukan bermaksud merend...</td>\n",
       "      <td>NEGATIF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              comment   label \n",
       "0   @sn5301679  pertanyaanya negara ini sudah maju...  NEGATIF\n",
       "1    @deppaykurniawan2016  Makanya itulah pentingn...  POSITIF\n",
       "2    @sn5301679  isu sensitif dan sering jadi komo...  NEGATIF\n",
       "3    @vivifitriasari  pernah pengalaman kerja di p...  NEGATIF\n",
       "4    @deppaykurniawan2016  Wah kebetulan bgt ya ma...  POSITIF\n",
       "5    @deppaykurniawan2016  Wah kebetulan bgt ya ma...  POSITIF\n",
       "6    @deppaykurniawan2016  Wah kebetulan bgt ya ma...  POSITIF\n",
       "7    @deppaykurniawan2016  Wah kebetulan bgt ya ma...  POSITIF\n",
       "8    @deppaykurniawan2016  Wah kebetulan bgt ya ma...  POSITIF\n",
       "9    @deppaykurniawan2016  Wah kebetulan bgt ya ma...  POSITIF\n",
       "10   @deppaykurniawan2016  Wah kebetulan bgt ya ma...  POSITIF\n",
       "11   @vivifitriasari  o.. saya dulu pernah gawe di...  POSITIF\n",
       "12   @sn5301679  Sorry bro, bukan bermaksud merend...  NEGATIF\n",
       "13   @sn5301679  Sorry bro, bukan bermaksud merend...  NEGATIF\n",
       "14   @sn5301679  Sorry bro, bukan bermaksud merend...  NEGATIF\n",
       "15   @sn5301679  Sorry bro, bukan bermaksud merend...  NEGATIF\n",
       "16   @sn5301679  Sorry bro, bukan bermaksud merend...  NEGATIF"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./dataset/dataTest.csv', sep=';', encoding='utf-8')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'ind' or 'en'\n",
    "LANGUAGE='ind'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanComment(comment, language):\n",
    "    try:\n",
    "        comment = re.sub(r'@\\w+|[^\\w\\s]', '', comment)\n",
    "        comment = re.sub(r'\\d+', '', comment)\n",
    "       \n",
    "        slang_dict = {}\n",
    "        filename = f'slang-{language}.txt'\n",
    "        if os.path.exists(filename) and os.path.getsize(filename) > 0:\n",
    "            with open(filename, 'r') as f:\n",
    "                for line in f:\n",
    "                    slang, formal = line.strip().split(',')\n",
    "                    slang_dict[slang] = formal\n",
    "\n",
    "        words = comment.split()\n",
    "        for i in range(len(words)):\n",
    "            if words[i] in slang_dict:\n",
    "                words[i] = slang_dict[words[i]]\n",
    "        comment = ' '.join(words)\n",
    "\n",
    "    except:\n",
    "        comment = ''\n",
    "        print(\"Err: Failed to clean comments\")\n",
    "    return comment.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "      <th>cleanComment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@sn5301679  pertanyaanya negara ini sudah maju...</td>\n",
       "      <td>NEGATIF</td>\n",
       "      <td>pertanyaanya negara ini sudah maju atau blm In...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@deppaykurniawan2016  Makanya itulah pentingn...</td>\n",
       "      <td>POSITIF</td>\n",
       "      <td>Makanya itulah pentingnya adaptasi Mau gimana ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@sn5301679  isu sensitif dan sering jadi komo...</td>\n",
       "      <td>NEGATIF</td>\n",
       "      <td>isu sensitif dan sering jadi komoditas politik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@vivifitriasari  pernah pengalaman kerja di p...</td>\n",
       "      <td>NEGATIF</td>\n",
       "      <td>pernah pengalaman kerja di perusahaan Teknolog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@deppaykurniawan2016  Wah kebetulan bgt ya ma...</td>\n",
       "      <td>POSITIF</td>\n",
       "      <td>Wah kebetulan bgt ya mas saya pernah kerja di ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment   label   \\\n",
       "0  @sn5301679  pertanyaanya negara ini sudah maju...  NEGATIF   \n",
       "1   @deppaykurniawan2016  Makanya itulah pentingn...  POSITIF   \n",
       "2   @sn5301679  isu sensitif dan sering jadi komo...  NEGATIF   \n",
       "3   @vivifitriasari  pernah pengalaman kerja di p...  NEGATIF   \n",
       "4   @deppaykurniawan2016  Wah kebetulan bgt ya ma...  POSITIF   \n",
       "\n",
       "                                        cleanComment  \n",
       "0  pertanyaanya negara ini sudah maju atau blm In...  \n",
       "1  Makanya itulah pentingnya adaptasi Mau gimana ...  \n",
       "2  isu sensitif dan sering jadi komoditas politik...  \n",
       "3  pernah pengalaman kerja di perusahaan Teknolog...  \n",
       "4  Wah kebetulan bgt ya mas saya pernah kerja di ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cleanComment'] = df['comment'].apply(lambda x: cleanComment(x, LANGUAGE))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case folding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caseFolding(cleanComment):\n",
    "    try:\n",
    "        cleanComment = cleanComment.lower()\n",
    "    except:\n",
    "        cleanComment = ''\n",
    "        print(\"Err: Failed to case folding\")\n",
    "    return cleanComment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleanComment</th>\n",
       "      <th>resultCaseFolding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pertanyaanya negara ini sudah maju atau blm In...</td>\n",
       "      <td>pertanyaanya negara ini sudah maju atau blm in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Makanya itulah pentingnya adaptasi Mau gimana ...</td>\n",
       "      <td>makanya itulah pentingnya adaptasi mau gimana ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>isu sensitif dan sering jadi komoditas politik...</td>\n",
       "      <td>isu sensitif dan sering jadi komoditas politik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pernah pengalaman kerja di perusahaan Teknolog...</td>\n",
       "      <td>pernah pengalaman kerja di perusahaan teknolog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wah kebetulan bgt ya mas saya pernah kerja di ...</td>\n",
       "      <td>wah kebetulan bgt ya mas saya pernah kerja di ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        cleanComment  \\\n",
       "0  pertanyaanya negara ini sudah maju atau blm In...   \n",
       "1  Makanya itulah pentingnya adaptasi Mau gimana ...   \n",
       "2  isu sensitif dan sering jadi komoditas politik...   \n",
       "3  pernah pengalaman kerja di perusahaan Teknolog...   \n",
       "4  Wah kebetulan bgt ya mas saya pernah kerja di ...   \n",
       "\n",
       "                                   resultCaseFolding  \n",
       "0  pertanyaanya negara ini sudah maju atau blm in...  \n",
       "1  makanya itulah pentingnya adaptasi mau gimana ...  \n",
       "2  isu sensitif dan sering jadi komoditas politik...  \n",
       "3  pernah pengalaman kerja di perusahaan teknolog...  \n",
       "4  wah kebetulan bgt ya mas saya pernah kerja di ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['resultCaseFolding'] = df['cleanComment'].apply(caseFolding)\n",
    "df[['cleanComment', 'resultCaseFolding']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(comments):\n",
    "    try:\n",
    "        words = comments.split(' ')\n",
    "        words = list(filter(None, words))  # hapus kata yang kosong\n",
    "    except Exception as e:\n",
    "        print(\"Err: Failed to tokenize due to\", str(e))\n",
    "        words = []\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resultCaseFolding</th>\n",
       "      <th>resultTokenize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pertanyaanya negara ini sudah maju atau blm in...</td>\n",
       "      <td>[pertanyaanya, negara, ini, sudah, maju, atau,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>makanya itulah pentingnya adaptasi mau gimana ...</td>\n",
       "      <td>[makanya, itulah, pentingnya, adaptasi, mau, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>isu sensitif dan sering jadi komoditas politik...</td>\n",
       "      <td>[isu, sensitif, dan, sering, jadi, komoditas, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pernah pengalaman kerja di perusahaan teknolog...</td>\n",
       "      <td>[pernah, pengalaman, kerja, di, perusahaan, te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wah kebetulan bgt ya mas saya pernah kerja di ...</td>\n",
       "      <td>[wah, kebetulan, bgt, ya, mas, saya, pernah, k...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   resultCaseFolding  \\\n",
       "0  pertanyaanya negara ini sudah maju atau blm in...   \n",
       "1  makanya itulah pentingnya adaptasi mau gimana ...   \n",
       "2  isu sensitif dan sering jadi komoditas politik...   \n",
       "3  pernah pengalaman kerja di perusahaan teknolog...   \n",
       "4  wah kebetulan bgt ya mas saya pernah kerja di ...   \n",
       "\n",
       "                                      resultTokenize  \n",
       "0  [pertanyaanya, negara, ini, sudah, maju, atau,...  \n",
       "1  [makanya, itulah, pentingnya, adaptasi, mau, g...  \n",
       "2  [isu, sensitif, dan, sering, jadi, komoditas, ...  \n",
       "3  [pernah, pengalaman, kerja, di, perusahaan, te...  \n",
       "4  [wah, kebetulan, bgt, ya, mas, saya, pernah, k...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['resultTokenize'] = df['resultCaseFolding'].apply(tokenize)\n",
    "df[['resultCaseFolding', 'resultTokenize']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Dell\n",
      "[nltk_data]     7300\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install nltk\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopwordRemoval(comments, language):\n",
    "    language_mapping = {\n",
    "        'en': 'english', \n",
    "        'ind': 'indonesian'\n",
    "    }\n",
    "\n",
    "    nltk_language = language_mapping.get(language, 'english') \n",
    "\n",
    "    stopWordRemoved = []\n",
    "    try:\n",
    "        stopList = stopwords.words(nltk_language)\n",
    "        filename = f'stopwords-{language}.txt'\n",
    "        if os.path.exists(filename) and os.path.getsize(filename) > 0:\n",
    "            with open(filename, 'r') as f:\n",
    "                stopList.extend(f.read().split('\\n')) \n",
    "        for word in comments:\n",
    "            if word not in stopList:\n",
    "                stopWordRemoved.append(word)\n",
    "    except:\n",
    "        print(\"Err: Failed to remove stopwords\")\n",
    "        \n",
    "    return stopWordRemoved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resultTokenize</th>\n",
       "      <th>resultStopword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[pertanyaanya, negara, ini, sudah, maju, atau,...</td>\n",
       "      <td>[pertanyaanya, negara, maju, blm, indonesia, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[makanya, itulah, pentingnya, adaptasi, mau, g...</td>\n",
       "      <td>[adaptasi, gimana, keadaannya, adaptasi, berta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[isu, sensitif, dan, sering, jadi, komoditas, ...</td>\n",
       "      <td>[isu, sensitif, komoditas, politik, win, solut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[pernah, pengalaman, kerja, di, perusahaan, te...</td>\n",
       "      <td>[pengalaman, kerja, perusahaan, teknologi, ind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[wah, kebetulan, bgt, ya, mas, saya, pernah, k...</td>\n",
       "      <td>[bgt, ya, mas, kerja, batam, tamatan, smp, sma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      resultTokenize  \\\n",
       "0  [pertanyaanya, negara, ini, sudah, maju, atau,...   \n",
       "1  [makanya, itulah, pentingnya, adaptasi, mau, g...   \n",
       "2  [isu, sensitif, dan, sering, jadi, komoditas, ...   \n",
       "3  [pernah, pengalaman, kerja, di, perusahaan, te...   \n",
       "4  [wah, kebetulan, bgt, ya, mas, saya, pernah, k...   \n",
       "\n",
       "                                      resultStopword  \n",
       "0  [pertanyaanya, negara, maju, blm, indonesia, t...  \n",
       "1  [adaptasi, gimana, keadaannya, adaptasi, berta...  \n",
       "2  [isu, sensitif, komoditas, politik, win, solut...  \n",
       "3  [pengalaman, kerja, perusahaan, teknologi, ind...  \n",
       "4  [bgt, ya, mas, kerja, batam, tamatan, smp, sma...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['resultStopword'] = df['resultTokenize'].apply(lambda x: stopwordRemoval(x, LANGUAGE))\n",
    "df[['resultTokenize', 'resultStopword']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hapus data kosong ([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [pertanyaanya, negara, maju, blm, indonesia, t...\n",
       "1     [adaptasi, gimana, keadaannya, adaptasi, berta...\n",
       "2     [isu, sensitif, komoditas, politik, win, solut...\n",
       "3     [pengalaman, kerja, perusahaan, teknologi, ind...\n",
       "4     [bgt, ya, mas, kerja, batam, tamatan, smp, sma...\n",
       "5     [bgt, ya, mas, kerja, batam, tamatan, smp, sma...\n",
       "6     [bgt, ya, mas, kerja, batam, tamatan, smp, sma...\n",
       "7     [bgt, ya, mas, kerja, batam, tamatan, smp, sma...\n",
       "8     [bgt, ya, mas, kerja, batam, tamatan, smp, sma...\n",
       "9     [bgt, ya, mas, kerja, batam, tamatan, smp, sma...\n",
       "10    [bgt, ya, mas, kerja, batam, tamatan, smp, sma...\n",
       "11    [o, gawe, rubycon, kawasan, industri, muka, ku...\n",
       "12    [sorry, bro, merendahkan, orang, tua, keras, k...\n",
       "13    [sorry, bro, merendahkan, orang, tua, keras, k...\n",
       "14    [sorry, bro, merendahkan, orang, tua, keras, k...\n",
       "15    [sorry, bro, merendahkan, orang, tua, keras, k...\n",
       "16    [sorry, bro, merendahkan, orang, tua, keras, k...\n",
       "Name: resultStopword, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['resultStopword'].apply(lambda x: len(x) > 0)]\n",
    "df['resultStopword']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install Sastrawi\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemmed_wrapper(term, language):\n",
    "    if language == 'ind':\n",
    "        factory = StemmerFactory()\n",
    "        stemmer = factory.create_stemmer()\n",
    "        return stemmer.stem(term)\n",
    "    else: \n",
    "        stemmer = PorterStemmer()\n",
    "        return stemmer.stem(term)\n",
    "\n",
    "def stemming(document, language):\n",
    "    return [stemmed_wrapper(term, language) for term in document]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resultStopword</th>\n",
       "      <th>resultStemming</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[pertanyaanya, negara, maju, blm, indonesia, t...</td>\n",
       "      <td>[pertanyaanya, negara, maju, blm, indonesia, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[adaptasi, gimana, keadaannya, adaptasi, berta...</td>\n",
       "      <td>[adaptasi, gimana, ada, adaptasi, tahan, bandi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[isu, sensitif, komoditas, politik, win, solut...</td>\n",
       "      <td>[isu, sensitif, komoditas, politik, win, solut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[pengalaman, kerja, perusahaan, teknologi, ind...</td>\n",
       "      <td>[alam, kerja, usaha, teknologi, indonesia, lan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[bgt, ya, mas, kerja, batam, tamatan, smp, sma...</td>\n",
       "      <td>[bgt, ya, mas, kerja, batam, tamat, smp, sma, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      resultStopword  \\\n",
       "0  [pertanyaanya, negara, maju, blm, indonesia, t...   \n",
       "1  [adaptasi, gimana, keadaannya, adaptasi, berta...   \n",
       "2  [isu, sensitif, komoditas, politik, win, solut...   \n",
       "3  [pengalaman, kerja, perusahaan, teknologi, ind...   \n",
       "4  [bgt, ya, mas, kerja, batam, tamatan, smp, sma...   \n",
       "\n",
       "                                      resultStemming  \n",
       "0  [pertanyaanya, negara, maju, blm, indonesia, t...  \n",
       "1  [adaptasi, gimana, ada, adaptasi, tahan, bandi...  \n",
       "2  [isu, sensitif, komoditas, politik, win, solut...  \n",
       "3  [alam, kerja, usaha, teknologi, indonesia, lan...  \n",
       "4  [bgt, ya, mas, kerja, batam, tamat, smp, sma, ...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['resultStemming'] = df['resultStopword'].apply(lambda x: stemming(x, LANGUAGE))\n",
    "df[['resultStopword', 'resultStemming']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\n",
    "    './output/data-clean-ind-test.csv', \n",
    "    columns=[\n",
    "        'comment', \n",
    "        'cleanComment',\n",
    "        'resultCaseFolding',\n",
    "        'resultTokenize',\n",
    "        'resultStopword',\n",
    "        'resultStemming',\n",
    "    ],\n",
    "    index=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
