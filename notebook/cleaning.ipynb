{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>username</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>text_preprocessed</th>\n",
       "      <th>polarity_score</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mon Dec 04 14:38:54 +0000 2023</td>\n",
       "      <td>lillkickity</td>\n",
       "      <td>plissss lah masa w ke surabaya pas covid mulu dah</td>\n",
       "      <td>['plissss', 'w', 'surabaya', 'pas', 'covid', '...</td>\n",
       "      <td>-1</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sun Dec 03 22:33:34 +0000 2023</td>\n",
       "      <td>Abiiiii789</td>\n",
       "      <td>mutiara yang enak di keluarga btw bakpia tugu ...</td>\n",
       "      <td>['mutiara', 'enak', 'keluarga', 'btw', 'bakpia...</td>\n",
       "      <td>-8</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sun Dec 03 13:21:32 +0000 2023</td>\n",
       "      <td>zona_raya</td>\n",
       "      <td>profil doni monardo mantan kepala bnpb dan ket...</td>\n",
       "      <td>['profil', 'doni', 'monardo', 'mantan', 'kepal...</td>\n",
       "      <td>-8</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sun Dec 03 13:18:30 +0000 2023</td>\n",
       "      <td>e100ss</td>\n",
       "      <td>doni monardo mantan ketua satgas covid berpula...</td>\n",
       "      <td>['doni', 'monardo', 'mantan', 'ketua', 'satgas...</td>\n",
       "      <td>-3</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thu Nov 30 15:55:40 +0000 2023</td>\n",
       "      <td>Sudrajat110</td>\n",
       "      <td>maxim penganti go massage go life dulu saya ik...</td>\n",
       "      <td>['maxim', 'anti', 'go', 'massage', 'go', 'life...</td>\n",
       "      <td>-4</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Sat Jun 17 05:15:30 +0000 2023</td>\n",
       "      <td>ANDROBET01</td>\n",
       "      <td>mantab jogetnya  link mendaftar</td>\n",
       "      <td>['mantab', 'joget', 'link', 'daftar']</td>\n",
       "      <td>-3</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Fri Jun 16 00:32:59 +0000 2023</td>\n",
       "      <td>RadioIdolaSMG</td>\n",
       "      <td>topik diskusi pagi ini  indonesia akan segera ...</td>\n",
       "      <td>['topik', 'diskusi', 'pagi', 'indonesia', 'mas...</td>\n",
       "      <td>-18</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Mon Jun 12 13:37:17 +0000 2023</td>\n",
       "      <td>fikimridho</td>\n",
       "      <td>sempronya di kos di surabaya sidangnya di ruma...</td>\n",
       "      <td>['sempronya', 'kos', 'surabaya', 'sidang', 'ru...</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Mon Jun 12 09:36:11 +0000 2023</td>\n",
       "      <td>superradioid</td>\n",
       "      <td>sr surabaya  mulai  juni  pelanggan kereta api...</td>\n",
       "      <td>['sr', 'surabaya', 'juni', 'langgan', 'kereta'...</td>\n",
       "      <td>-17</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Sun Jun 11 11:37:51 +0000 2023</td>\n",
       "      <td>Fita_Shanty</td>\n",
       "      <td>jkt sepatu bangun lab terus di bongkar dari  l...</td>\n",
       "      <td>['jkt', 'sepatu', 'bangun', 'lab', 'bongkar', ...</td>\n",
       "      <td>-9</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        created_at       username  \\\n",
       "0   Mon Dec 04 14:38:54 +0000 2023    lillkickity   \n",
       "1   Sun Dec 03 22:33:34 +0000 2023     Abiiiii789   \n",
       "2   Sun Dec 03 13:21:32 +0000 2023      zona_raya   \n",
       "3   Sun Dec 03 13:18:30 +0000 2023         e100ss   \n",
       "4   Thu Nov 30 15:55:40 +0000 2023    Sudrajat110   \n",
       "..                             ...            ...   \n",
       "95  Sat Jun 17 05:15:30 +0000 2023     ANDROBET01   \n",
       "96  Fri Jun 16 00:32:59 +0000 2023  RadioIdolaSMG   \n",
       "97  Mon Jun 12 13:37:17 +0000 2023     fikimridho   \n",
       "98  Mon Jun 12 09:36:11 +0000 2023   superradioid   \n",
       "99  Sun Jun 11 11:37:51 +0000 2023    Fita_Shanty   \n",
       "\n",
       "                                           text_clean  \\\n",
       "0   plissss lah masa w ke surabaya pas covid mulu dah   \n",
       "1   mutiara yang enak di keluarga btw bakpia tugu ...   \n",
       "2   profil doni monardo mantan kepala bnpb dan ket...   \n",
       "3   doni monardo mantan ketua satgas covid berpula...   \n",
       "4   maxim penganti go massage go life dulu saya ik...   \n",
       "..                                                ...   \n",
       "95                    mantab jogetnya  link mendaftar   \n",
       "96  topik diskusi pagi ini  indonesia akan segera ...   \n",
       "97  sempronya di kos di surabaya sidangnya di ruma...   \n",
       "98  sr surabaya  mulai  juni  pelanggan kereta api...   \n",
       "99  jkt sepatu bangun lab terus di bongkar dari  l...   \n",
       "\n",
       "                                    text_preprocessed  polarity_score  \\\n",
       "0   ['plissss', 'w', 'surabaya', 'pas', 'covid', '...              -1   \n",
       "1   ['mutiara', 'enak', 'keluarga', 'btw', 'bakpia...              -8   \n",
       "2   ['profil', 'doni', 'monardo', 'mantan', 'kepal...              -8   \n",
       "3   ['doni', 'monardo', 'mantan', 'ketua', 'satgas...              -3   \n",
       "4   ['maxim', 'anti', 'go', 'massage', 'go', 'life...              -4   \n",
       "..                                                ...             ...   \n",
       "95              ['mantab', 'joget', 'link', 'daftar']              -3   \n",
       "96  ['topik', 'diskusi', 'pagi', 'indonesia', 'mas...             -18   \n",
       "97  ['sempronya', 'kos', 'surabaya', 'sidang', 'ru...               5   \n",
       "98  ['sr', 'surabaya', 'juni', 'langgan', 'kereta'...             -17   \n",
       "99  ['jkt', 'sepatu', 'bangun', 'lab', 'bongkar', ...              -9   \n",
       "\n",
       "    polarity  \n",
       "0   negative  \n",
       "1   negative  \n",
       "2   negative  \n",
       "3   negative  \n",
       "4   negative  \n",
       "..       ...  \n",
       "95  negative  \n",
       "96  negative  \n",
       "97  positive  \n",
       "98  negative  \n",
       "99  negative  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../dataset/tweets_sentiment_covid_fix.csv')\n",
    "df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'ind' or 'en'\n",
    "LANGUAGE='ind'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "created_at           object\n",
       "username             object\n",
       "text_clean           object\n",
       "text_preprocessed    object\n",
       "polarity_score        int64\n",
       "polarity             object\n",
       "dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Unnamed: 4', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NO                     int64\n",
       "NAMA_PENGGUNA         object\n",
       "COMMENT               object\n",
       "SENTIMEN              object\n",
       "cleanComment          object\n",
       "resultCaseFolding     object\n",
       "resultReplaceSlang    object\n",
       "resultTokenize        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['text_cleaning'] = df['COMMENT'].astype(str)\n",
    "df = df.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id_komentar      object\n",
       "nama_akun        object\n",
       "tanggal          object\n",
       "text_cleaning    object\n",
       "sentimen         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanComment(comment):\n",
    "    try:\n",
    "        # misal ada \"kawan-kawan\"\n",
    "        comment = re.sub(r'(?<=\\w)-(?=\\w)', 'STRIP', comment)\n",
    "        comment = re.sub(r'http\\S+|www\\S+', '', comment)\n",
    "        comment = re.sub(r'@\\w+|[^\\w\\s-]|(?<!\\w)-(?!\\w)|\\d+|(?<=\\n)[IVXLCDM]+', ' ', comment)\n",
    "        comment = re.sub(r'\\s+', ' ', comment)\n",
    "        comment = comment.replace('STRIP', '-')\n",
    "        comment = comment.replace('\\n', ' ')\n",
    "        return comment.strip()\n",
    "    except Exception as e: \n",
    "        print(f\"Err: Failed to clean comments due to {str(e)}\")\n",
    "        return comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_clean</th>\n",
       "      <th>cleanComment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>plissss lah masa w ke surabaya pas covid mulu dah</td>\n",
       "      <td>plissss lah masa w ke surabaya pas covid mulu dah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mutiara yang enak di keluarga btw bakpia tugu ...</td>\n",
       "      <td>mutiara yang enak di keluarga btw bakpia tugu ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>profil doni monardo mantan kepala bnpb dan ket...</td>\n",
       "      <td>profil doni monardo mantan kepala bnpb dan ket...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>doni monardo mantan ketua satgas covid berpula...</td>\n",
       "      <td>doni monardo mantan ketua satgas covid berpula...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>maxim penganti go massage go life dulu saya ik...</td>\n",
       "      <td>maxim penganti go massage go life dulu saya ik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>mantab jogetnya  link mendaftar</td>\n",
       "      <td>mantab jogetnya link mendaftar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>topik diskusi pagi ini  indonesia akan segera ...</td>\n",
       "      <td>topik diskusi pagi ini indonesia akan segera m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>sempronya di kos di surabaya sidangnya di ruma...</td>\n",
       "      <td>sempronya di kos di surabaya sidangnya di ruma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>sr surabaya  mulai  juni  pelanggan kereta api...</td>\n",
       "      <td>sr surabaya mulai juni pelanggan kereta api ka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>jkt sepatu bangun lab terus di bongkar dari  l...</td>\n",
       "      <td>jkt sepatu bangun lab terus di bongkar dari la...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           text_clean  \\\n",
       "0   plissss lah masa w ke surabaya pas covid mulu dah   \n",
       "1   mutiara yang enak di keluarga btw bakpia tugu ...   \n",
       "2   profil doni monardo mantan kepala bnpb dan ket...   \n",
       "3   doni monardo mantan ketua satgas covid berpula...   \n",
       "4   maxim penganti go massage go life dulu saya ik...   \n",
       "..                                                ...   \n",
       "95                    mantab jogetnya  link mendaftar   \n",
       "96  topik diskusi pagi ini  indonesia akan segera ...   \n",
       "97  sempronya di kos di surabaya sidangnya di ruma...   \n",
       "98  sr surabaya  mulai  juni  pelanggan kereta api...   \n",
       "99  jkt sepatu bangun lab terus di bongkar dari  l...   \n",
       "\n",
       "                                         cleanComment  \n",
       "0   plissss lah masa w ke surabaya pas covid mulu dah  \n",
       "1   mutiara yang enak di keluarga btw bakpia tugu ...  \n",
       "2   profil doni monardo mantan kepala bnpb dan ket...  \n",
       "3   doni monardo mantan ketua satgas covid berpula...  \n",
       "4   maxim penganti go massage go life dulu saya ik...  \n",
       "..                                                ...  \n",
       "95                     mantab jogetnya link mendaftar  \n",
       "96  topik diskusi pagi ini indonesia akan segera m...  \n",
       "97  sempronya di kos di surabaya sidangnya di ruma...  \n",
       "98  sr surabaya mulai juni pelanggan kereta api ka...  \n",
       "99  jkt sepatu bangun lab terus di bongkar dari la...  \n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cleanComment'] = df['text_clean'].apply(lambda x: cleanComment(x))\n",
    "df[['text_clean', 'cleanComment']].head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case folding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caseFolding(comment):\n",
    "    try:\n",
    "        str(comment)\n",
    "        cleanComment = comment.lower()\n",
    "        return cleanComment     \n",
    "    except Exception as e: \n",
    "        print(f\"Err: Failed to case folding due to {str(e)}\")\n",
    "        return comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleanComment</th>\n",
       "      <th>resultCaseFolding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>plissss lah masa w ke surabaya pas covid mulu dah</td>\n",
       "      <td>plissss lah masa w ke surabaya pas covid mulu dah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mutiara yang enak di keluarga btw bakpia tugu ...</td>\n",
       "      <td>mutiara yang enak di keluarga btw bakpia tugu ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>profil doni monardo mantan kepala bnpb dan ket...</td>\n",
       "      <td>profil doni monardo mantan kepala bnpb dan ket...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>doni monardo mantan ketua satgas covid berpula...</td>\n",
       "      <td>doni monardo mantan ketua satgas covid berpula...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>maxim penganti go massage go life dulu saya ik...</td>\n",
       "      <td>maxim penganti go massage go life dulu saya ik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>mantab jogetnya link mendaftar</td>\n",
       "      <td>mantab jogetnya link mendaftar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>topik diskusi pagi ini indonesia akan segera m...</td>\n",
       "      <td>topik diskusi pagi ini indonesia akan segera m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>sempronya di kos di surabaya sidangnya di ruma...</td>\n",
       "      <td>sempronya di kos di surabaya sidangnya di ruma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>sr surabaya mulai juni pelanggan kereta api ka...</td>\n",
       "      <td>sr surabaya mulai juni pelanggan kereta api ka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>jkt sepatu bangun lab terus di bongkar dari la...</td>\n",
       "      <td>jkt sepatu bangun lab terus di bongkar dari la...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         cleanComment  \\\n",
       "0   plissss lah masa w ke surabaya pas covid mulu dah   \n",
       "1   mutiara yang enak di keluarga btw bakpia tugu ...   \n",
       "2   profil doni monardo mantan kepala bnpb dan ket...   \n",
       "3   doni monardo mantan ketua satgas covid berpula...   \n",
       "4   maxim penganti go massage go life dulu saya ik...   \n",
       "..                                                ...   \n",
       "95                     mantab jogetnya link mendaftar   \n",
       "96  topik diskusi pagi ini indonesia akan segera m...   \n",
       "97  sempronya di kos di surabaya sidangnya di ruma...   \n",
       "98  sr surabaya mulai juni pelanggan kereta api ka...   \n",
       "99  jkt sepatu bangun lab terus di bongkar dari la...   \n",
       "\n",
       "                                    resultCaseFolding  \n",
       "0   plissss lah masa w ke surabaya pas covid mulu dah  \n",
       "1   mutiara yang enak di keluarga btw bakpia tugu ...  \n",
       "2   profil doni monardo mantan kepala bnpb dan ket...  \n",
       "3   doni monardo mantan ketua satgas covid berpula...  \n",
       "4   maxim penganti go massage go life dulu saya ik...  \n",
       "..                                                ...  \n",
       "95                     mantab jogetnya link mendaftar  \n",
       "96  topik diskusi pagi ini indonesia akan segera m...  \n",
       "97  sempronya di kos di surabaya sidangnya di ruma...  \n",
       "98  sr surabaya mulai juni pelanggan kereta api ka...  \n",
       "99  jkt sepatu bangun lab terus di bongkar dari la...  \n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['resultCaseFolding'] = df['cleanComment'].apply(caseFolding)\n",
    "df[['cleanComment', 'resultCaseFolding']].head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slang Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replaceSlangWords(comment, language):\n",
    "    try:\n",
    "        slang_dict = {}\n",
    "        filename = f'../slang/slang-{language}.txt'\n",
    "        if os.path.exists(filename) and os.path.getsize(filename) > 0:\n",
    "            with open(filename, 'r') as f:\n",
    "                for line in f:\n",
    "                    slang, formal = line.strip().split(',')\n",
    "                    slang_dict[slang] = formal\n",
    "\n",
    "        words = comment.split()\n",
    "        for i in range(len(words)):\n",
    "            if words[i] in slang_dict:\n",
    "                words[i] = slang_dict[words[i]]\n",
    "        return ' '.join(words)\n",
    "    except Exception as e:\n",
    "        print(f\"Err: Failed to replace slang words due to {str(e)}\")\n",
    "        return comment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resultCaseFolding</th>\n",
       "      <th>resultReplaceSlang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>plissss lah masa w ke surabaya pas covid mulu dah</td>\n",
       "      <td>plissss lah masa w ke surabaya pas covid mulu dah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mutiara yang enak di keluarga btw bakpia tugu ...</td>\n",
       "      <td>mutiara yang enak di keluarga btw bakpia tugu ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>profil doni monardo mantan kepala bnpb dan ket...</td>\n",
       "      <td>profil doni monardo mantan kepala bnpb dan ket...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>doni monardo mantan ketua satgas covid berpula...</td>\n",
       "      <td>doni monardo mantan ketua satgas covid berpula...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>maxim penganti go massage go life dulu saya ik...</td>\n",
       "      <td>maxim penganti go massage go life dulu saya ik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1300</th>\n",
       "      <td>heheh ketemu setaon skali belum tentu sejak pa...</td>\n",
       "      <td>heheh ketemu setahun sekali belum tentu sejak ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1301</th>\n",
       "      <td>kamu kuliah dimana nder aku sebelum pandemi di...</td>\n",
       "      <td>kamu kuliah dimana nder aku sebelum pandemi di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1302</th>\n",
       "      <td>terima kasih kepada para wisatawan yang sudah ...</td>\n",
       "      <td>terima kasih kepada para wisatawan yang sudah ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1303</th>\n",
       "      <td>kanwil kemenkumham jatim wisnu nugroho dewanto...</td>\n",
       "      <td>kanwil kemenkumham jatim wisnu nugroho dewanto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>kanwilkemenkumham jatim wisnu nugroho dewanto ...</td>\n",
       "      <td>kanwilkemenkumham jatim wisnu nugroho dewanto ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1305 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      resultCaseFolding  \\\n",
       "0     plissss lah masa w ke surabaya pas covid mulu dah   \n",
       "1     mutiara yang enak di keluarga btw bakpia tugu ...   \n",
       "2     profil doni monardo mantan kepala bnpb dan ket...   \n",
       "3     doni monardo mantan ketua satgas covid berpula...   \n",
       "4     maxim penganti go massage go life dulu saya ik...   \n",
       "...                                                 ...   \n",
       "1300  heheh ketemu setaon skali belum tentu sejak pa...   \n",
       "1301  kamu kuliah dimana nder aku sebelum pandemi di...   \n",
       "1302  terima kasih kepada para wisatawan yang sudah ...   \n",
       "1303  kanwil kemenkumham jatim wisnu nugroho dewanto...   \n",
       "1304  kanwilkemenkumham jatim wisnu nugroho dewanto ...   \n",
       "\n",
       "                                     resultReplaceSlang  \n",
       "0     plissss lah masa w ke surabaya pas covid mulu dah  \n",
       "1     mutiara yang enak di keluarga btw bakpia tugu ...  \n",
       "2     profil doni monardo mantan kepala bnpb dan ket...  \n",
       "3     doni monardo mantan ketua satgas covid berpula...  \n",
       "4     maxim penganti go massage go life dulu saya ik...  \n",
       "...                                                 ...  \n",
       "1300  heheh ketemu setahun sekali belum tentu sejak ...  \n",
       "1301  kamu kuliah dimana nder aku sebelum pandemi di...  \n",
       "1302  terima kasih kepada para wisatawan yang sudah ...  \n",
       "1303  kanwil kemenkumham jatim wisnu nugroho dewanto...  \n",
       "1304  kanwilkemenkumham jatim wisnu nugroho dewanto ...  \n",
       "\n",
       "[1305 rows x 2 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['resultReplaceSlang'] = df['resultCaseFolding'].apply(lambda x: replaceSlangWords(x, LANGUAGE))\n",
    "df[['resultCaseFolding', 'resultReplaceSlang']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(comment):\n",
    "    try:\n",
    "        words = comment.split(' ')\n",
    "        words = list(filter(None, words)) \n",
    "\n",
    "        return words\n",
    "    except Exception as e:\n",
    "        print(\"Err: Failed to tokenize due to\", str(e))\n",
    "        return comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resultReplaceSlang</th>\n",
       "      <th>resultTokenize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>plissss lah masa w ke surabaya pas covid mulu dah</td>\n",
       "      <td>[plissss, lah, masa, w, ke, surabaya, pas, cov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mutiara yang enak di keluarga btw bakpia tugu ...</td>\n",
       "      <td>[mutiara, yang, enak, di, keluarga, btw, bakpi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>profil doni monardo mantan kepala bnpb dan ket...</td>\n",
       "      <td>[profil, doni, monardo, mantan, kepala, bnpb, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>doni monardo mantan ketua satgas covid berpula...</td>\n",
       "      <td>[doni, monardo, mantan, ketua, satgas, covid, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>maxim penganti go massage go life dulu saya ik...</td>\n",
       "      <td>[maxim, penganti, go, massage, go, life, dulu,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bi sebut qris selamatkan indonesia dari krisis...</td>\n",
       "      <td>[bi, sebut, qris, selamatkan, indonesia, dari,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>buanyak sekali usia an yang pengangguran setel...</td>\n",
       "      <td>[buanyak, sekali, usia, an, yang, pengangguran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>naufal tapi hasilnya bagus dan konsisten kan w...</td>\n",
       "      <td>[naufal, tapi, hasilnya, bagus, dan, konsisten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tweet kota solo adalah kota dgn pertumbuhan te...</td>\n",
       "      <td>[tweet, kota, solo, adalah, kota, dgn, pertumb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rail clinic kembali hadir untuk masyarakat set...</td>\n",
       "      <td>[rail, clinic, kembali, hadir, untuk, masyarak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>rail clinic kembali hadir untuk masyarakat set...</td>\n",
       "      <td>[rail, clinic, kembali, hadir, untuk, masyarak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tahun lalu dunia bener runtuh kakak lakiku men...</td>\n",
       "      <td>[tahun, lalu, dunia, bener, runtuh, kakak, lak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hmm lupa inget antara ke surabayamakassar tuh ...</td>\n",
       "      <td>[hmm, lupa, inget, antara, ke, surabayamakassa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mall kios masih tutup kosong sepi harga beras ...</td>\n",
       "      <td>[mall, kios, masih, tutup, kosong, sepi, harga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>komisi pemberantasan korupsi kpk menggeledah b...</td>\n",
       "      <td>[komisi, pemberantasan, korupsi, kpk, menggele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>alhamdulillah mas jalur surabaya konsisten mul...</td>\n",
       "      <td>[alhamdulillah, mas, jalur, surabaya, konsiste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>semua happy bcs mama setelah tahun baru naik k...</td>\n",
       "      <td>[semua, happy, bcs, mama, setelah, tahun, baru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>yang terakhir aku lupa perkara surabaya gempa ...</td>\n",
       "      <td>[yang, terakhir, aku, lupa, perkara, surabaya,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>awal² sma ortu bangkrut lulus langsung keterim...</td>\n",
       "      <td>[awal², sma, ortu, bangkrut, lulus, langsung, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>nakula bu pernah bikin mantan walikota surabay...</td>\n",
       "      <td>[nakula, bu, pernah, bikin, mantan, walikota, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   resultReplaceSlang  \\\n",
       "0   plissss lah masa w ke surabaya pas covid mulu dah   \n",
       "1   mutiara yang enak di keluarga btw bakpia tugu ...   \n",
       "2   profil doni monardo mantan kepala bnpb dan ket...   \n",
       "3   doni monardo mantan ketua satgas covid berpula...   \n",
       "4   maxim penganti go massage go life dulu saya ik...   \n",
       "5   bi sebut qris selamatkan indonesia dari krisis...   \n",
       "6   buanyak sekali usia an yang pengangguran setel...   \n",
       "7   naufal tapi hasilnya bagus dan konsisten kan w...   \n",
       "8   tweet kota solo adalah kota dgn pertumbuhan te...   \n",
       "9   rail clinic kembali hadir untuk masyarakat set...   \n",
       "10  rail clinic kembali hadir untuk masyarakat set...   \n",
       "11  tahun lalu dunia bener runtuh kakak lakiku men...   \n",
       "12  hmm lupa inget antara ke surabayamakassar tuh ...   \n",
       "13  mall kios masih tutup kosong sepi harga beras ...   \n",
       "14  komisi pemberantasan korupsi kpk menggeledah b...   \n",
       "15  alhamdulillah mas jalur surabaya konsisten mul...   \n",
       "16  semua happy bcs mama setelah tahun baru naik k...   \n",
       "17  yang terakhir aku lupa perkara surabaya gempa ...   \n",
       "18  awal² sma ortu bangkrut lulus langsung keterim...   \n",
       "19  nakula bu pernah bikin mantan walikota surabay...   \n",
       "\n",
       "                                       resultTokenize  \n",
       "0   [plissss, lah, masa, w, ke, surabaya, pas, cov...  \n",
       "1   [mutiara, yang, enak, di, keluarga, btw, bakpi...  \n",
       "2   [profil, doni, monardo, mantan, kepala, bnpb, ...  \n",
       "3   [doni, monardo, mantan, ketua, satgas, covid, ...  \n",
       "4   [maxim, penganti, go, massage, go, life, dulu,...  \n",
       "5   [bi, sebut, qris, selamatkan, indonesia, dari,...  \n",
       "6   [buanyak, sekali, usia, an, yang, pengangguran...  \n",
       "7   [naufal, tapi, hasilnya, bagus, dan, konsisten...  \n",
       "8   [tweet, kota, solo, adalah, kota, dgn, pertumb...  \n",
       "9   [rail, clinic, kembali, hadir, untuk, masyarak...  \n",
       "10  [rail, clinic, kembali, hadir, untuk, masyarak...  \n",
       "11  [tahun, lalu, dunia, bener, runtuh, kakak, lak...  \n",
       "12  [hmm, lupa, inget, antara, ke, surabayamakassa...  \n",
       "13  [mall, kios, masih, tutup, kosong, sepi, harga...  \n",
       "14  [komisi, pemberantasan, korupsi, kpk, menggele...  \n",
       "15  [alhamdulillah, mas, jalur, surabaya, konsiste...  \n",
       "16  [semua, happy, bcs, mama, setelah, tahun, baru...  \n",
       "17  [yang, terakhir, aku, lupa, perkara, surabaya,...  \n",
       "18  [awal², sma, ortu, bangkrut, lulus, langsung, ...  \n",
       "19  [nakula, bu, pernah, bikin, mantan, walikota, ...  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['resultTokenize'] = df['resultReplaceSlang'].apply(tokenize)\n",
    "df[['resultReplaceSlang', 'resultTokenize']].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop Word Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Dell\n",
      "[nltk_data]     7300\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install nltk\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopwordRemoval(comments, language):\n",
    "    language_mapping = {\n",
    "        'en': 'english', \n",
    "        'ind': 'indonesian'\n",
    "    }\n",
    "\n",
    "    nltk_language = language_mapping.get(language, 'english') \n",
    "    stopWordRemoved = []\n",
    "    \n",
    "    try:\n",
    "        stopList = stopwords.words(nltk_language)\n",
    "        filename = f'../stopword/stopword-{language}.txt' \n",
    "        if os.path.exists(filename) and os.path.getsize(filename) > 0:\n",
    "            with open(filename, 'r') as f:\n",
    "                stopList.extend(f.read().split('\\n')) \n",
    "        for word in comments:\n",
    "            if word not in stopList:\n",
    "                stopWordRemoved.append(word)\n",
    "\n",
    "        return stopWordRemoved  \n",
    "    except Exception as e:  \n",
    "        print(f\"Err: Failed to remove stopwords due to {str(e)}\")\n",
    "        return comments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resultTokenize</th>\n",
       "      <th>resultStopword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[plissss, lah, masa, w, ke, surabaya, pas, cov...</td>\n",
       "      <td>[plissss, surabaya, pas, covid, mulu, dah]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[mutiara, yang, enak, di, keluarga, btw, bakpi...</td>\n",
       "      <td>[mutiara, enak, keluarga, btw, bakpia, tugu, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[profil, doni, monardo, mantan, kepala, bnpb, ...</td>\n",
       "      <td>[profil, doni, monardo, mantan, kepala, bnpb, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[doni, monardo, mantan, ketua, satgas, covid, ...</td>\n",
       "      <td>[doni, monardo, mantan, ketua, satgas, covid, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[maxim, penganti, go, massage, go, life, dulu,...</td>\n",
       "      <td>[maxim, penganti, go, massage, go, life, gomas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[bi, sebut, qris, selamatkan, indonesia, dari,...</td>\n",
       "      <td>[bi, qris, selamatkan, indonesia, krisis, pand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[buanyak, sekali, usia, an, yang, pengangguran...</td>\n",
       "      <td>[buanyak, usia, an, pengangguran, covidf, sura...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[naufal, tapi, hasilnya, bagus, dan, konsisten...</td>\n",
       "      <td>[naufal, hasilnya, bagus, konsisten, tergebrak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[tweet, kota, solo, adalah, kota, dgn, pertumb...</td>\n",
       "      <td>[tweet, kota, solo, kota, dgn, pertumbuhan, te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[rail, clinic, kembali, hadir, untuk, masyarak...</td>\n",
       "      <td>[rail, clinic, hadir, masyarakat, vakum, akiba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[rail, clinic, kembali, hadir, untuk, masyarak...</td>\n",
       "      <td>[rail, clinic, hadir, masyarakat, vakum, akiba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[tahun, lalu, dunia, bener, runtuh, kakak, lak...</td>\n",
       "      <td>[dunia, bener, runtuh, kakak, lakiku, meningga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[hmm, lupa, inget, antara, ke, surabayamakassa...</td>\n",
       "      <td>[hmm, lupa, inget, surabayamakassar, tuh, mask...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[mall, kios, masih, tutup, kosong, sepi, harga...</td>\n",
       "      <td>[mall, kios, tutup, kosong, sepi, harga, beras...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[komisi, pemberantasan, korupsi, kpk, menggele...</td>\n",
       "      <td>[komisi, pemberantasan, korupsi, kpk, menggele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[alhamdulillah, mas, jalur, surabaya, konsiste...</td>\n",
       "      <td>[alhamdulillah, mas, jalur, surabaya, konsiste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[semua, happy, bcs, mama, setelah, tahun, baru...</td>\n",
       "      <td>[happy, bcs, mama, kereta, pas, covid, dinas, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[yang, terakhir, aku, lupa, perkara, surabaya,...</td>\n",
       "      <td>[lupa, perkara, surabaya, gempa, covid]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[awal², sma, ortu, bangkrut, lulus, langsung, ...</td>\n",
       "      <td>[awal², sma, ortu, bangkrut, lulus, langsung, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[nakula, bu, pernah, bikin, mantan, walikota, ...</td>\n",
       "      <td>[nakula, bu, bikin, mantan, walikota, surabaya...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       resultTokenize  \\\n",
       "0   [plissss, lah, masa, w, ke, surabaya, pas, cov...   \n",
       "1   [mutiara, yang, enak, di, keluarga, btw, bakpi...   \n",
       "2   [profil, doni, monardo, mantan, kepala, bnpb, ...   \n",
       "3   [doni, monardo, mantan, ketua, satgas, covid, ...   \n",
       "4   [maxim, penganti, go, massage, go, life, dulu,...   \n",
       "5   [bi, sebut, qris, selamatkan, indonesia, dari,...   \n",
       "6   [buanyak, sekali, usia, an, yang, pengangguran...   \n",
       "7   [naufal, tapi, hasilnya, bagus, dan, konsisten...   \n",
       "8   [tweet, kota, solo, adalah, kota, dgn, pertumb...   \n",
       "9   [rail, clinic, kembali, hadir, untuk, masyarak...   \n",
       "10  [rail, clinic, kembali, hadir, untuk, masyarak...   \n",
       "11  [tahun, lalu, dunia, bener, runtuh, kakak, lak...   \n",
       "12  [hmm, lupa, inget, antara, ke, surabayamakassa...   \n",
       "13  [mall, kios, masih, tutup, kosong, sepi, harga...   \n",
       "14  [komisi, pemberantasan, korupsi, kpk, menggele...   \n",
       "15  [alhamdulillah, mas, jalur, surabaya, konsiste...   \n",
       "16  [semua, happy, bcs, mama, setelah, tahun, baru...   \n",
       "17  [yang, terakhir, aku, lupa, perkara, surabaya,...   \n",
       "18  [awal², sma, ortu, bangkrut, lulus, langsung, ...   \n",
       "19  [nakula, bu, pernah, bikin, mantan, walikota, ...   \n",
       "\n",
       "                                       resultStopword  \n",
       "0          [plissss, surabaya, pas, covid, mulu, dah]  \n",
       "1   [mutiara, enak, keluarga, btw, bakpia, tugu, l...  \n",
       "2   [profil, doni, monardo, mantan, kepala, bnpb, ...  \n",
       "3   [doni, monardo, mantan, ketua, satgas, covid, ...  \n",
       "4   [maxim, penganti, go, massage, go, life, gomas...  \n",
       "5   [bi, qris, selamatkan, indonesia, krisis, pand...  \n",
       "6   [buanyak, usia, an, pengangguran, covidf, sura...  \n",
       "7   [naufal, hasilnya, bagus, konsisten, tergebrak...  \n",
       "8   [tweet, kota, solo, kota, dgn, pertumbuhan, te...  \n",
       "9   [rail, clinic, hadir, masyarakat, vakum, akiba...  \n",
       "10  [rail, clinic, hadir, masyarakat, vakum, akiba...  \n",
       "11  [dunia, bener, runtuh, kakak, lakiku, meningga...  \n",
       "12  [hmm, lupa, inget, surabayamakassar, tuh, mask...  \n",
       "13  [mall, kios, tutup, kosong, sepi, harga, beras...  \n",
       "14  [komisi, pemberantasan, korupsi, kpk, menggele...  \n",
       "15  [alhamdulillah, mas, jalur, surabaya, konsiste...  \n",
       "16  [happy, bcs, mama, kereta, pas, covid, dinas, ...  \n",
       "17            [lupa, perkara, surabaya, gempa, covid]  \n",
       "18  [awal², sma, ortu, bangkrut, lulus, langsung, ...  \n",
       "19  [nakula, bu, bikin, mantan, walikota, surabaya...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['resultStopword'] = df['resultTokenize'].apply(lambda x: stopwordRemoval(x, LANGUAGE))\n",
    "df[['resultTokenize', 'resultStopword']].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hapus data kosong ([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resultStopword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[plissss, surabaya, pas, covid, mulu, dah]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[mutiara, enak, keluarga, btw, bakpia, tugu, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[profil, doni, monardo, mantan, kepala, bnpb, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[doni, monardo, mantan, ketua, satgas, covid, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[maxim, penganti, go, massage, go, life, gomas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1300</th>\n",
       "      <td>[heheh, ketemu, setahun, pandemi, sdh, taon, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1301</th>\n",
       "      <td>[kuliah, dimana, nder, pandemi, surabaya, jata...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1302</th>\n",
       "      <td>[terima, kasih, wisatawan, berkunjung, gili, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1303</th>\n",
       "      <td>[kanwil, kemenkumham, jatim, wisnu, nugroho, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>[kanwilkemenkumham, jatim, wisnu, nugroho, dew...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1305 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         resultStopword\n",
       "0            [plissss, surabaya, pas, covid, mulu, dah]\n",
       "1     [mutiara, enak, keluarga, btw, bakpia, tugu, l...\n",
       "2     [profil, doni, monardo, mantan, kepala, bnpb, ...\n",
       "3     [doni, monardo, mantan, ketua, satgas, covid, ...\n",
       "4     [maxim, penganti, go, massage, go, life, gomas...\n",
       "...                                                 ...\n",
       "1300  [heheh, ketemu, setahun, pandemi, sdh, taon, g...\n",
       "1301  [kuliah, dimana, nder, pandemi, surabaya, jata...\n",
       "1302  [terima, kasih, wisatawan, berkunjung, gili, t...\n",
       "1303  [kanwil, kemenkumham, jatim, wisnu, nugroho, d...\n",
       "1304  [kanwilkemenkumham, jatim, wisnu, nugroho, dew...\n",
       "\n",
       "[1305 rows x 1 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['resultStopword'].apply(lambda x: len(x) > 0)]\n",
    "df[['resultStopword']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install Sastrawi\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemmed_wrapper(term, language):\n",
    "    try:\n",
    "        if language == 'ind':\n",
    "            factory = StemmerFactory()\n",
    "            stemmer = factory.create_stemmer()\n",
    "            return stemmer.stem(term)\n",
    "        else: \n",
    "            stemmer = PorterStemmer()\n",
    "            return stemmer.stem(term)\n",
    "    except Exception as e:\n",
    "        print(f\"Err: Failed to stem term '{term}' due to {str(e)}\")\n",
    "        return term \n",
    "\n",
    "def stemming(document, language):\n",
    "    return [stemmed_wrapper(term, language) for term in document]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['resultStemming'] = df['resultStopword'].apply(lambda x: stemming(x, LANGUAGE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resultStopword</th>\n",
       "      <th>resultStemming</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[plissss, surabaya, pas, covid, mulu, dah]</td>\n",
       "      <td>[plissss, surabaya, pas, covid, mulu, dah]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[mutiara, enak, keluarga, btw, bakpia, tugu, l...</td>\n",
       "      <td>[mutiara, enak, keluarga, btw, bakpia, tugu, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[profil, doni, monardo, mantan, kepala, bnpb, ...</td>\n",
       "      <td>[profil, doni, monardo, mantan, kepala, bnpb, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[doni, monardo, mantan, ketua, satgas, covid, ...</td>\n",
       "      <td>[doni, monardo, mantan, ketua, satgas, covid, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[maxim, penganti, go, massage, go, life, gomas...</td>\n",
       "      <td>[maxim, anti, go, massage, go, life, gomassage...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1300</th>\n",
       "      <td>[heheh, ketemu, setahun, pandemi, sdh, taon, g...</td>\n",
       "      <td>[heheh, ketemu, tahun, pandemi, sdh, taon, gak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1301</th>\n",
       "      <td>[kuliah, dimana, nder, pandemi, surabaya, jata...</td>\n",
       "      <td>[kuliah, mana, nder, pandemi, surabaya, jatah,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1302</th>\n",
       "      <td>[terima, kasih, wisatawan, berkunjung, gili, t...</td>\n",
       "      <td>[terima, kasih, wisatawan, kunjung, gili, traw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1303</th>\n",
       "      <td>[kanwil, kemenkumham, jatim, wisnu, nugroho, d...</td>\n",
       "      <td>[kanwil, kemenkumham, jatim, wisnu, nugroho, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>[kanwilkemenkumham, jatim, wisnu, nugroho, dew...</td>\n",
       "      <td>[kanwilkemenkumham, jatim, wisnu, nugroho, dew...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1305 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         resultStopword  \\\n",
       "0            [plissss, surabaya, pas, covid, mulu, dah]   \n",
       "1     [mutiara, enak, keluarga, btw, bakpia, tugu, l...   \n",
       "2     [profil, doni, monardo, mantan, kepala, bnpb, ...   \n",
       "3     [doni, monardo, mantan, ketua, satgas, covid, ...   \n",
       "4     [maxim, penganti, go, massage, go, life, gomas...   \n",
       "...                                                 ...   \n",
       "1300  [heheh, ketemu, setahun, pandemi, sdh, taon, g...   \n",
       "1301  [kuliah, dimana, nder, pandemi, surabaya, jata...   \n",
       "1302  [terima, kasih, wisatawan, berkunjung, gili, t...   \n",
       "1303  [kanwil, kemenkumham, jatim, wisnu, nugroho, d...   \n",
       "1304  [kanwilkemenkumham, jatim, wisnu, nugroho, dew...   \n",
       "\n",
       "                                         resultStemming  \n",
       "0            [plissss, surabaya, pas, covid, mulu, dah]  \n",
       "1     [mutiara, enak, keluarga, btw, bakpia, tugu, l...  \n",
       "2     [profil, doni, monardo, mantan, kepala, bnpb, ...  \n",
       "3     [doni, monardo, mantan, ketua, satgas, covid, ...  \n",
       "4     [maxim, anti, go, massage, go, life, gomassage...  \n",
       "...                                                 ...  \n",
       "1300  [heheh, ketemu, tahun, pandemi, sdh, taon, gak...  \n",
       "1301  [kuliah, mana, nder, pandemi, surabaya, jatah,...  \n",
       "1302  [terima, kasih, wisatawan, kunjung, gili, traw...  \n",
       "1303  [kanwil, kemenkumham, jatim, wisnu, nugroho, d...  \n",
       "1304  [kanwilkemenkumham, jatim, wisnu, nugroho, dew...  \n",
       "\n",
       "[1305 rows x 2 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['resultStopword', 'resultStemming']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\n",
    "    './output/CLEAN-dataset_tweet_sentimen_tayangan_tv.csv',\n",
    "    columns=[\n",
    "        'Id',\n",
    "        'Sentiment',\n",
    "        'Acara TV',\n",
    "        'Jumlah Retweet',\n",
    "        'Text Tweet',\n",
    "        'cleanComment',\n",
    "        'resultCaseFolding',\n",
    "        'resultReplaceSlang',\n",
    "        'resultTokenize',\n",
    "        'resultStopword',\n",
    "        'resultStemming',\n",
    "    ],\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\n",
    "    './output/CLEAN-dataset_tweet_sentiment_cellular_service_provider.csv',\n",
    "    columns=df.columns,\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\n",
    "    './output/CLEAN-dataset_tweet_sentiment_opini_film.csv',\n",
    "    columns=df.columns,\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\n",
    "    '../output/CLEAN-dataset_mobil_listrik.csv',\n",
    "    columns=df.columns,\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\n",
    "    './output/data-clean-ind-new.csv', \n",
    "    columns=[\n",
    "        'Comment', \n",
    "        'cleanComment',\n",
    "        'resultCaseFolding',\n",
    "        'resultReplaceSlang',\n",
    "        'resultTokenize',\n",
    "        'resultStopword',\n",
    "        'resultStemming',\n",
    "    ],\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\n",
    "    './output/data-clean-ind-new.xlsx', \n",
    "    columns=[\n",
    "        'Comment', \n",
    "        'cleanComment',\n",
    "        'resultCaseFolding',\n",
    "        'resultReplaceSlang',\n",
    "        'resultTokenize',\n",
    "        'resultStopword',\n",
    "        'resultStemming',\n",
    "    ],\n",
    "    index=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
